{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WheelerClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQY5tAF/uKGXFypoR5yHWC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshmansamvith/Wheeler-Classifier/blob/master/WheelerClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hij72x8rTLS2",
        "colab_type": "code",
        "outputId": "8e82f229-5a61-4e94-e0ed-01efc98b5a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HBVeoMcVjOC",
        "colab_type": "text"
      },
      "source": [
        "#Create Directories \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTdemg10COk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
        "from tensorflow.keras.models import Sequential \n",
        "\n",
        "training_dir = '/content/drive/My Drive/Wheeler Classifier/Training'\n",
        "validation_dir = '/content/drive/My Drive/Wheeler Classifier/Validation'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euDqCGwBuH70",
        "colab_type": "text"
      },
      "source": [
        "#Creating Transfer Model(Inception)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYHJbhi0vFhx",
        "colab_type": "code",
        "outputId": "93ebbc08-78c6-46b6-8758-22d36919a29a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "exist_model = InceptionV3(input_shape=(150, 150, 3), include_top=False)\n",
        "for layer in exist_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "exist_model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2rEJaEnx_sm",
        "colab_type": "text"
      },
      "source": [
        "#Creating Our Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0EDQtdjyVnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(exist_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycpM6l8zv67h",
        "colab_type": "text"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fdsc9gCBICH",
        "colab_type": "text"
      },
      "source": [
        "#Image Data Generators\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q09GV_KEBMSw",
        "colab_type": "code",
        "outputId": "9ccf5bf7-863e-4534-b803-9b40cc4b58d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "training_datagen = ImageDataGenerator(rescale=1/255.0, \n",
        "                                      rotation_range=40, \n",
        "                                      width_shift_range=0.5,\n",
        "                                      height_shift_range=0.5, \n",
        "                                      shear_range=0.2,\n",
        "                                      vertical_flip=True,\n",
        "                                      horizontal_flip=True)\n",
        "\n",
        "training_generator = training_datagen.flow_from_directory(training_dir, \n",
        "                                                          target_size=(150, 150), \n",
        "                                                          batch_size=10,\n",
        "                                                          class_mode='binary')\n",
        "\n",
        "validation_datagen =  ImageDataGenerator(rescale=1/255.0,)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dir, \n",
        "                                                          target_size=(150, 150), \n",
        "                                                          batch_size=10,\n",
        "                                                          class_mode='binary')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 250 images belonging to 2 classes.\n",
            "Found 158 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjmu73wVE3ys",
        "colab_type": "text"
      },
      "source": [
        "#Fitting Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O770uXCEq3x",
        "colab_type": "code",
        "outputId": "e43cb021-16b7-451b-f564-18747039c40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.0001), metrics=['accuracy'])\n",
        "history = model.fit_generator(training_generator,\n",
        "                    epochs=200,\n",
        "                    steps_per_epoch=250//10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=158//10,\n",
        "                    verbose=1\n",
        "                   )\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-b5e223a2ec7d>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/200\n",
            "16/25 [==================>...........] - ETA: 30s - loss: 0.4882 - accuracy: 0.9438"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 136s 5s/step - loss: 0.3146 - accuracy: 0.9640 - val_loss: 7.6365 - val_accuracy: 0.4733\n",
            "Epoch 2/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.2061 - accuracy: 0.9880 - val_loss: 7.2724 - val_accuracy: 0.4733\n",
            "Epoch 3/200\n",
            "25/25 [==============================] - 6s 232ms/step - loss: 0.1230 - accuracy: 0.9880 - val_loss: 7.1261 - val_accuracy: 0.4800\n",
            "Epoch 4/200\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 0.1441 - accuracy: 0.9840 - val_loss: 6.9486 - val_accuracy: 0.4867\n",
            "Epoch 5/200\n",
            "25/25 [==============================] - 6s 250ms/step - loss: 0.1666 - accuracy: 0.9800 - val_loss: 8.0291 - val_accuracy: 0.4867\n",
            "Epoch 6/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.1098 - accuracy: 0.9880 - val_loss: 7.3715 - val_accuracy: 0.4933\n",
            "Epoch 7/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.1430 - accuracy: 0.9840 - val_loss: 7.3063 - val_accuracy: 0.5000\n",
            "Epoch 8/200\n",
            "25/25 [==============================] - 6s 242ms/step - loss: 0.1032 - accuracy: 0.9840 - val_loss: 8.5511 - val_accuracy: 0.4733\n",
            "Epoch 9/200\n",
            "25/25 [==============================] - 6s 235ms/step - loss: 0.0880 - accuracy: 0.9760 - val_loss: 6.4955 - val_accuracy: 0.5000\n",
            "Epoch 10/200\n",
            "25/25 [==============================] - 6s 257ms/step - loss: 0.1887 - accuracy: 0.9800 - val_loss: 6.8743 - val_accuracy: 0.4867\n",
            "Epoch 11/200\n",
            "25/25 [==============================] - 6s 253ms/step - loss: 0.1356 - accuracy: 0.9800 - val_loss: 9.1633 - val_accuracy: 0.4933\n",
            "Epoch 12/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.2302 - accuracy: 0.9840 - val_loss: 0.8804 - val_accuracy: 0.8000\n",
            "Epoch 13/200\n",
            "25/25 [==============================] - 6s 235ms/step - loss: 0.1558 - accuracy: 0.9840 - val_loss: 4.6270 - val_accuracy: 0.5133\n",
            "Epoch 14/200\n",
            "25/25 [==============================] - 6s 224ms/step - loss: 0.1478 - accuracy: 0.9760 - val_loss: 7.3081 - val_accuracy: 0.4867\n",
            "Epoch 15/200\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.1522 - accuracy: 0.9800 - val_loss: 5.4216 - val_accuracy: 0.4867\n",
            "Epoch 16/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.0475 - accuracy: 0.9880 - val_loss: 8.4141 - val_accuracy: 0.4733\n",
            "Epoch 17/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.1057 - accuracy: 0.9840 - val_loss: 11.5870 - val_accuracy: 0.4867\n",
            "Epoch 18/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.0901 - accuracy: 0.9840 - val_loss: 8.6758 - val_accuracy: 0.4800\n",
            "Epoch 19/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.1780 - accuracy: 0.9800 - val_loss: 3.8423 - val_accuracy: 0.5800\n",
            "Epoch 20/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.1496 - accuracy: 0.9840 - val_loss: 8.0787 - val_accuracy: 0.4867\n",
            "Epoch 21/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.0587 - accuracy: 0.9880 - val_loss: 8.6819 - val_accuracy: 0.4733\n",
            "Epoch 22/200\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 0.1171 - accuracy: 0.9840 - val_loss: 12.0557 - val_accuracy: 0.5000\n",
            "Epoch 23/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.1574 - accuracy: 0.9880 - val_loss: 5.7305 - val_accuracy: 0.5400\n",
            "Epoch 24/200\n",
            "25/25 [==============================] - 6s 242ms/step - loss: 0.0984 - accuracy: 0.9880 - val_loss: 12.6266 - val_accuracy: 0.5000\n",
            "Epoch 25/200\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.0726 - accuracy: 0.9880 - val_loss: 9.3472 - val_accuracy: 0.4933\n",
            "Epoch 26/200\n",
            "25/25 [==============================] - 7s 262ms/step - loss: 0.1454 - accuracy: 0.9840 - val_loss: 19.0816 - val_accuracy: 0.4933\n",
            "Epoch 27/200\n",
            "25/25 [==============================] - 7s 263ms/step - loss: 0.1336 - accuracy: 0.9880 - val_loss: 11.1910 - val_accuracy: 0.4733\n",
            "Epoch 28/200\n",
            "25/25 [==============================] - 6s 254ms/step - loss: 0.1292 - accuracy: 0.9880 - val_loss: 11.5362 - val_accuracy: 0.5000\n",
            "Epoch 29/200\n",
            "25/25 [==============================] - 6s 254ms/step - loss: 0.0080 - accuracy: 0.9960 - val_loss: 9.3453 - val_accuracy: 0.4933\n",
            "Epoch 30/200\n",
            "25/25 [==============================] - 6s 253ms/step - loss: 0.1541 - accuracy: 0.9840 - val_loss: 4.0247 - val_accuracy: 0.6400\n",
            "Epoch 31/200\n",
            "25/25 [==============================] - 6s 253ms/step - loss: 0.1367 - accuracy: 0.9840 - val_loss: 12.8408 - val_accuracy: 0.4800\n",
            "Epoch 32/200\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.1303 - accuracy: 0.9920 - val_loss: 12.2278 - val_accuracy: 0.5067\n",
            "Epoch 33/200\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.1966 - accuracy: 0.9840 - val_loss: 14.1112 - val_accuracy: 0.4800\n",
            "Epoch 34/200\n",
            "25/25 [==============================] - 6s 254ms/step - loss: 0.1503 - accuracy: 0.9840 - val_loss: 12.0480 - val_accuracy: 0.5000\n",
            "Epoch 35/200\n",
            "25/25 [==============================] - 6s 220ms/step - loss: 0.1112 - accuracy: 0.9800 - val_loss: 11.9690 - val_accuracy: 0.4733\n",
            "Epoch 36/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.1019 - accuracy: 0.9880 - val_loss: 15.2737 - val_accuracy: 0.5000\n",
            "Epoch 37/200\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.1422 - accuracy: 0.9840 - val_loss: 6.5592 - val_accuracy: 0.5533\n",
            "Epoch 38/200\n",
            "25/25 [==============================] - 6s 244ms/step - loss: 0.0865 - accuracy: 0.9880 - val_loss: 7.7925 - val_accuracy: 0.5467\n",
            "Epoch 39/200\n",
            "25/25 [==============================] - 7s 261ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 10.3745 - val_accuracy: 0.5333\n",
            "Epoch 40/200\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 0.0402 - accuracy: 0.9920 - val_loss: 13.0767 - val_accuracy: 0.5000\n",
            "Epoch 41/200\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.0797 - accuracy: 0.9920 - val_loss: 11.3658 - val_accuracy: 0.5133\n",
            "Epoch 42/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.1155 - accuracy: 0.9920 - val_loss: 10.7757 - val_accuracy: 0.5067\n",
            "Epoch 43/200\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.1286 - accuracy: 0.9840 - val_loss: 7.1694 - val_accuracy: 0.5933\n",
            "Epoch 44/200\n",
            "25/25 [==============================] - 6s 244ms/step - loss: 0.1449 - accuracy: 0.9880 - val_loss: 11.9058 - val_accuracy: 0.4867\n",
            "Epoch 45/200\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.1139 - accuracy: 0.9840 - val_loss: 17.8712 - val_accuracy: 0.4933\n",
            "Epoch 46/200\n",
            "25/25 [==============================] - 6s 242ms/step - loss: 0.0754 - accuracy: 0.9920 - val_loss: 12.2189 - val_accuracy: 0.5000\n",
            "Epoch 47/200\n",
            "25/25 [==============================] - 6s 250ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 12.1031 - val_accuracy: 0.5000\n",
            "Epoch 48/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.3013 - accuracy: 0.9760 - val_loss: 9.6583 - val_accuracy: 0.5400\n",
            "Epoch 49/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 13.9059 - val_accuracy: 0.4867\n",
            "Epoch 50/200\n",
            "25/25 [==============================] - 6s 229ms/step - loss: 0.0592 - accuracy: 0.9920 - val_loss: 16.8135 - val_accuracy: 0.4933\n",
            "Epoch 51/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.1411 - accuracy: 0.9800 - val_loss: 17.4556 - val_accuracy: 0.5000\n",
            "Epoch 52/200\n",
            "25/25 [==============================] - 6s 230ms/step - loss: 0.1310 - accuracy: 0.9920 - val_loss: 16.3460 - val_accuracy: 0.4933\n",
            "Epoch 53/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.0277 - accuracy: 0.9960 - val_loss: 11.0776 - val_accuracy: 0.5733\n",
            "Epoch 54/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.1738 - accuracy: 0.9840 - val_loss: 13.8595 - val_accuracy: 0.4933\n",
            "Epoch 55/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.1164 - accuracy: 0.9880 - val_loss: 8.3453 - val_accuracy: 0.6133\n",
            "Epoch 56/200\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 0.0737 - accuracy: 0.9920 - val_loss: 16.5030 - val_accuracy: 0.4800\n",
            "Epoch 57/200\n",
            "25/25 [==============================] - 6s 235ms/step - loss: 0.0393 - accuracy: 0.9920 - val_loss: 17.0043 - val_accuracy: 0.4867\n",
            "Epoch 58/200\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 0.0436 - accuracy: 0.9960 - val_loss: 6.9362 - val_accuracy: 0.6533\n",
            "Epoch 59/200\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.1255 - accuracy: 0.9880 - val_loss: 6.8420 - val_accuracy: 0.6800\n",
            "Epoch 60/200\n",
            "25/25 [==============================] - 6s 236ms/step - loss: 0.0734 - accuracy: 0.9840 - val_loss: 15.7490 - val_accuracy: 0.4800\n",
            "Epoch 61/200\n",
            "25/25 [==============================] - 6s 239ms/step - loss: 0.1459 - accuracy: 0.9800 - val_loss: 22.3874 - val_accuracy: 0.4933\n",
            "Epoch 62/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.0633 - accuracy: 0.9960 - val_loss: 12.7880 - val_accuracy: 0.5067\n",
            "Epoch 63/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.1491 - accuracy: 0.9840 - val_loss: 10.7864 - val_accuracy: 0.5533\n",
            "Epoch 64/200\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.0880 - accuracy: 0.9960 - val_loss: 10.8574 - val_accuracy: 0.5533\n",
            "Epoch 65/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.0222 - accuracy: 0.9960 - val_loss: 10.0571 - val_accuracy: 0.6000\n",
            "Epoch 66/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.0740 - accuracy: 0.9960 - val_loss: 11.4955 - val_accuracy: 0.5533\n",
            "Epoch 67/200\n",
            "25/25 [==============================] - 6s 242ms/step - loss: 0.0489 - accuracy: 0.9960 - val_loss: 4.6261 - val_accuracy: 0.7400\n",
            "Epoch 68/200\n",
            "25/25 [==============================] - 6s 244ms/step - loss: 0.0070 - accuracy: 0.9960 - val_loss: 5.3895 - val_accuracy: 0.7400\n",
            "Epoch 69/200\n",
            "25/25 [==============================] - 6s 231ms/step - loss: 0.1516 - accuracy: 0.9880 - val_loss: 14.4620 - val_accuracy: 0.5533\n",
            "Epoch 70/200\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 0.0330 - accuracy: 0.9920 - val_loss: 16.8922 - val_accuracy: 0.5267\n",
            "Epoch 71/200\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.7094 - val_accuracy: 0.7600\n",
            "Epoch 72/200\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 0.0877 - accuracy: 0.9800 - val_loss: 21.8630 - val_accuracy: 0.4867\n",
            "Epoch 73/200\n",
            "25/25 [==============================] - 6s 257ms/step - loss: 0.0820 - accuracy: 0.9960 - val_loss: 15.0763 - val_accuracy: 0.5533\n",
            "Epoch 74/200\n",
            "25/25 [==============================] - 6s 256ms/step - loss: 0.2095 - accuracy: 0.9840 - val_loss: 20.9285 - val_accuracy: 0.4933\n",
            "Epoch 75/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.0251 - accuracy: 0.9960 - val_loss: 14.9865 - val_accuracy: 0.5667\n",
            "Epoch 76/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.1342 - accuracy: 0.9880 - val_loss: 27.4221 - val_accuracy: 0.4867\n",
            "Epoch 77/200\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.3489 - accuracy: 0.9880 - val_loss: 8.9734 - val_accuracy: 0.6133\n",
            "Epoch 78/200\n",
            "25/25 [==============================] - 5s 218ms/step - loss: 0.1358 - accuracy: 0.9920 - val_loss: 14.0876 - val_accuracy: 0.5400\n",
            "Epoch 79/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 3.9502e-05 - accuracy: 1.0000 - val_loss: 12.6872 - val_accuracy: 0.5800\n",
            "Epoch 80/200\n",
            "25/25 [==============================] - 6s 250ms/step - loss: 0.1171 - accuracy: 0.9840 - val_loss: 24.8210 - val_accuracy: 0.5000\n",
            "Epoch 81/200\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 0.0428 - accuracy: 0.9920 - val_loss: 16.2616 - val_accuracy: 0.5133\n",
            "Epoch 82/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.0900 - accuracy: 0.9920 - val_loss: 12.5014 - val_accuracy: 0.5733\n",
            "Epoch 83/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.2234 - accuracy: 0.9840 - val_loss: 12.0614 - val_accuracy: 0.5533\n",
            "Epoch 84/200\n",
            "25/25 [==============================] - 6s 256ms/step - loss: 0.0775 - accuracy: 0.9880 - val_loss: 19.7641 - val_accuracy: 0.4867\n",
            "Epoch 85/200\n",
            "25/25 [==============================] - 5s 220ms/step - loss: 0.0567 - accuracy: 0.9960 - val_loss: 11.2621 - val_accuracy: 0.5733\n",
            "Epoch 86/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.0460 - accuracy: 0.9960 - val_loss: 8.2038 - val_accuracy: 0.6400\n",
            "Epoch 87/200\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.1622 - accuracy: 0.9840 - val_loss: 12.4726 - val_accuracy: 0.5600\n",
            "Epoch 88/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 11.7070 - val_accuracy: 0.5533\n",
            "Epoch 89/200\n",
            "25/25 [==============================] - 6s 250ms/step - loss: 0.0048 - accuracy: 0.9960 - val_loss: 9.7466 - val_accuracy: 0.6133\n",
            "Epoch 90/200\n",
            "25/25 [==============================] - 6s 242ms/step - loss: 0.0730 - accuracy: 0.9880 - val_loss: 22.4675 - val_accuracy: 0.4667\n",
            "Epoch 91/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.1512 - accuracy: 0.9840 - val_loss: 27.3284 - val_accuracy: 0.4933\n",
            "Epoch 92/200\n",
            "25/25 [==============================] - 6s 239ms/step - loss: 0.1142 - accuracy: 0.9880 - val_loss: 15.5543 - val_accuracy: 0.5400\n",
            "Epoch 93/200\n",
            "25/25 [==============================] - 6s 256ms/step - loss: 0.0291 - accuracy: 0.9880 - val_loss: 14.1663 - val_accuracy: 0.5800\n",
            "Epoch 94/200\n",
            "25/25 [==============================] - 6s 254ms/step - loss: 1.0270e-04 - accuracy: 1.0000 - val_loss: 20.0180 - val_accuracy: 0.5000\n",
            "Epoch 95/200\n",
            "25/25 [==============================] - 7s 261ms/step - loss: 0.1419 - accuracy: 0.9920 - val_loss: 8.1520 - val_accuracy: 0.6733\n",
            "Epoch 96/200\n",
            "25/25 [==============================] - 6s 257ms/step - loss: 2.6552e-04 - accuracy: 1.0000 - val_loss: 14.3558 - val_accuracy: 0.5933\n",
            "Epoch 97/200\n",
            "25/25 [==============================] - 6s 256ms/step - loss: 1.8719e-06 - accuracy: 1.0000 - val_loss: 14.7097 - val_accuracy: 0.5800\n",
            "Epoch 98/200\n",
            "25/25 [==============================] - 6s 250ms/step - loss: 0.0466 - accuracy: 0.9960 - val_loss: 21.6265 - val_accuracy: 0.5133\n",
            "Epoch 99/200\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 0.1484 - accuracy: 0.9920 - val_loss: 19.3549 - val_accuracy: 0.5067\n",
            "Epoch 100/200\n",
            "25/25 [==============================] - 6s 223ms/step - loss: 0.0464 - accuracy: 0.9960 - val_loss: 15.3889 - val_accuracy: 0.5533\n",
            "Epoch 101/200\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.1226 - accuracy: 0.9880 - val_loss: 15.5902 - val_accuracy: 0.5533\n",
            "Epoch 102/200\n",
            "25/25 [==============================] - 6s 256ms/step - loss: 0.2290 - accuracy: 0.9840 - val_loss: 16.1378 - val_accuracy: 0.5267\n",
            "Epoch 103/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.3352 - accuracy: 0.9880 - val_loss: 7.2510 - val_accuracy: 0.6600\n",
            "Epoch 104/200\n",
            "25/25 [==============================] - 7s 264ms/step - loss: 0.1401 - accuracy: 0.9920 - val_loss: 7.6493 - val_accuracy: 0.6400\n",
            "Epoch 105/200\n",
            "25/25 [==============================] - 6s 260ms/step - loss: 0.1525 - accuracy: 0.9800 - val_loss: 13.2716 - val_accuracy: 0.5400\n",
            "Epoch 106/200\n",
            "25/25 [==============================] - 6s 260ms/step - loss: 0.1513 - accuracy: 0.9840 - val_loss: 13.9548 - val_accuracy: 0.5400\n",
            "Epoch 107/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.1917 - accuracy: 0.9840 - val_loss: 14.8885 - val_accuracy: 0.5267\n",
            "Epoch 108/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.0839 - accuracy: 0.9880 - val_loss: 11.4294 - val_accuracy: 0.5733\n",
            "Epoch 109/200\n",
            "25/25 [==============================] - 6s 230ms/step - loss: 0.0104 - accuracy: 0.9920 - val_loss: 15.2342 - val_accuracy: 0.5133\n",
            "Epoch 110/200\n",
            "25/25 [==============================] - 6s 238ms/step - loss: 0.2350 - accuracy: 0.9800 - val_loss: 10.5869 - val_accuracy: 0.6000\n",
            "Epoch 111/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.0517 - accuracy: 0.9960 - val_loss: 22.1757 - val_accuracy: 0.4667\n",
            "Epoch 112/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.0987 - accuracy: 0.9960 - val_loss: 15.8705 - val_accuracy: 0.5067\n",
            "Epoch 113/200\n",
            "25/25 [==============================] - 6s 244ms/step - loss: 0.0216 - accuracy: 0.9960 - val_loss: 14.6133 - val_accuracy: 0.5467\n",
            "Epoch 114/200\n",
            "25/25 [==============================] - 6s 244ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 27.9137 - val_accuracy: 0.4867\n",
            "Epoch 115/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.1324 - accuracy: 0.9960 - val_loss: 20.7648 - val_accuracy: 0.4867\n",
            "Epoch 116/200\n",
            "25/25 [==============================] - 5s 218ms/step - loss: 0.1438 - accuracy: 0.9880 - val_loss: 12.5906 - val_accuracy: 0.5533\n",
            "Epoch 117/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.0645 - accuracy: 0.9920 - val_loss: 11.7377 - val_accuracy: 0.5733\n",
            "Epoch 118/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.0867 - accuracy: 0.9960 - val_loss: 13.9469 - val_accuracy: 0.5400\n",
            "Epoch 119/200\n",
            "25/25 [==============================] - 6s 231ms/step - loss: 0.0897 - accuracy: 0.9880 - val_loss: 19.5438 - val_accuracy: 0.4867\n",
            "Epoch 120/200\n",
            "25/25 [==============================] - 6s 239ms/step - loss: 0.0471 - accuracy: 0.9920 - val_loss: 19.2813 - val_accuracy: 0.4867\n",
            "Epoch 121/200\n",
            "25/25 [==============================] - 6s 232ms/step - loss: 0.0236 - accuracy: 0.9960 - val_loss: 10.5986 - val_accuracy: 0.6000\n",
            "Epoch 122/200\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.1269 - accuracy: 0.9920 - val_loss: 13.4282 - val_accuracy: 0.5467\n",
            "Epoch 123/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.1264 - accuracy: 0.9960 - val_loss: 9.9888 - val_accuracy: 0.6067\n",
            "Epoch 124/200\n",
            "25/25 [==============================] - 6s 230ms/step - loss: 1.0960e-05 - accuracy: 1.0000 - val_loss: 12.9021 - val_accuracy: 0.5533\n",
            "Epoch 125/200\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 3.1621e-05 - accuracy: 1.0000 - val_loss: 22.9640 - val_accuracy: 0.5000\n",
            "Epoch 126/200\n",
            "25/25 [==============================] - 6s 242ms/step - loss: 0.1410 - accuracy: 0.9880 - val_loss: 24.5769 - val_accuracy: 0.4933\n",
            "Epoch 127/200\n",
            "25/25 [==============================] - 6s 239ms/step - loss: 0.0601 - accuracy: 0.9880 - val_loss: 15.2031 - val_accuracy: 0.5667\n",
            "Epoch 128/200\n",
            "25/25 [==============================] - 6s 238ms/step - loss: 0.0539 - accuracy: 0.9920 - val_loss: 19.4381 - val_accuracy: 0.5333\n",
            "Epoch 129/200\n",
            "25/25 [==============================] - 6s 238ms/step - loss: 0.0934 - accuracy: 0.9920 - val_loss: 19.4417 - val_accuracy: 0.5200\n",
            "Epoch 130/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.0597 - accuracy: 0.9920 - val_loss: 19.3060 - val_accuracy: 0.4933\n",
            "Epoch 131/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.0815 - accuracy: 0.9960 - val_loss: 8.4284 - val_accuracy: 0.6533\n",
            "Epoch 132/200\n",
            "25/25 [==============================] - 6s 242ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 19.8056 - val_accuracy: 0.4867\n",
            "Epoch 133/200\n",
            "25/25 [==============================] - 6s 237ms/step - loss: 3.4523e-04 - accuracy: 1.0000 - val_loss: 16.7202 - val_accuracy: 0.5400\n",
            "Epoch 134/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.0224 - accuracy: 0.9880 - val_loss: 10.9894 - val_accuracy: 0.6200\n",
            "Epoch 135/200\n",
            "25/25 [==============================] - 6s 239ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 16.5168 - val_accuracy: 0.5733\n",
            "Epoch 136/200\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 2.9445e-08 - accuracy: 1.0000 - val_loss: 17.2583 - val_accuracy: 0.5667\n",
            "Epoch 137/200\n",
            "25/25 [==============================] - 6s 222ms/step - loss: 0.2049 - accuracy: 0.9880 - val_loss: 8.9607 - val_accuracy: 0.6333\n",
            "Epoch 138/200\n",
            "25/25 [==============================] - 7s 266ms/step - loss: 0.0300 - accuracy: 0.9920 - val_loss: 9.5859 - val_accuracy: 0.6133\n",
            "Epoch 139/200\n",
            "25/25 [==============================] - 7s 263ms/step - loss: 6.8133e-06 - accuracy: 1.0000 - val_loss: 9.2137 - val_accuracy: 0.6200\n",
            "Epoch 140/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.0936 - accuracy: 0.9920 - val_loss: 15.0405 - val_accuracy: 0.5733\n",
            "Epoch 141/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.1199 - accuracy: 0.9960 - val_loss: 11.5304 - val_accuracy: 0.6133\n",
            "Epoch 142/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.1159 - accuracy: 0.9880 - val_loss: 17.6255 - val_accuracy: 0.5333\n",
            "Epoch 143/200\n",
            "25/25 [==============================] - 6s 236ms/step - loss: 0.0797 - accuracy: 0.9840 - val_loss: 22.8881 - val_accuracy: 0.5000\n",
            "Epoch 144/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.1311 - accuracy: 0.9920 - val_loss: 9.7151 - val_accuracy: 0.6333\n",
            "Epoch 145/200\n",
            "25/25 [==============================] - 6s 230ms/step - loss: 0.0355 - accuracy: 0.9880 - val_loss: 19.7232 - val_accuracy: 0.4933\n",
            "Epoch 146/200\n",
            "25/25 [==============================] - 6s 242ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 11.6048 - val_accuracy: 0.6067\n",
            "Epoch 147/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.0888 - accuracy: 0.9840 - val_loss: 18.5559 - val_accuracy: 0.5400\n",
            "Epoch 148/200\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 2.2420e-05 - accuracy: 1.0000 - val_loss: 19.4987 - val_accuracy: 0.5333\n",
            "Epoch 149/200\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 8.4063e-05 - accuracy: 1.0000 - val_loss: 16.8900 - val_accuracy: 0.5600\n",
            "Epoch 150/200\n",
            "25/25 [==============================] - 6s 250ms/step - loss: 0.0502 - accuracy: 0.9920 - val_loss: 18.3753 - val_accuracy: 0.5533\n",
            "Epoch 151/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.0254 - accuracy: 0.9880 - val_loss: 11.3728 - val_accuracy: 0.6200\n",
            "Epoch 152/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 1.4819e-06 - accuracy: 1.0000 - val_loss: 11.4139 - val_accuracy: 0.6133\n",
            "Epoch 153/200\n",
            "25/25 [==============================] - 5s 217ms/step - loss: 0.1154 - accuracy: 0.9920 - val_loss: 15.4609 - val_accuracy: 0.5800\n",
            "Epoch 154/200\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.0816 - accuracy: 0.9960 - val_loss: 12.2108 - val_accuracy: 0.6267\n",
            "Epoch 155/200\n",
            "25/25 [==============================] - 5s 219ms/step - loss: 0.0948 - accuracy: 0.9920 - val_loss: 19.1809 - val_accuracy: 0.5200\n",
            "Epoch 156/200\n",
            "25/25 [==============================] - 6s 234ms/step - loss: 5.2366e-06 - accuracy: 1.0000 - val_loss: 18.0819 - val_accuracy: 0.5400\n",
            "Epoch 157/200\n",
            "25/25 [==============================] - 6s 245ms/step - loss: 0.0521 - accuracy: 0.9920 - val_loss: 16.5035 - val_accuracy: 0.5800\n",
            "Epoch 158/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 7.4237e-06 - accuracy: 1.0000 - val_loss: 19.6678 - val_accuracy: 0.5333\n",
            "Epoch 159/200\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 0.3703 - accuracy: 0.9800 - val_loss: 15.6864 - val_accuracy: 0.5600\n",
            "Epoch 160/200\n",
            "25/25 [==============================] - 7s 261ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 20.7865 - val_accuracy: 0.5000\n",
            "Epoch 161/200\n",
            "25/25 [==============================] - 6s 253ms/step - loss: 3.4412e-06 - accuracy: 1.0000 - val_loss: 19.7748 - val_accuracy: 0.5067\n",
            "Epoch 162/200\n",
            "25/25 [==============================] - 6s 232ms/step - loss: 0.0963 - accuracy: 0.9880 - val_loss: 32.8144 - val_accuracy: 0.5000\n",
            "Epoch 163/200\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.1818 - accuracy: 0.9920 - val_loss: 14.5045 - val_accuracy: 0.5533\n",
            "Epoch 164/200\n",
            "25/25 [==============================] - 6s 250ms/step - loss: 0.1256 - accuracy: 0.9960 - val_loss: 12.2146 - val_accuracy: 0.5600\n",
            "Epoch 165/200\n",
            "25/25 [==============================] - 6s 246ms/step - loss: 0.0529 - accuracy: 0.9880 - val_loss: 19.1060 - val_accuracy: 0.5133\n",
            "Epoch 166/200\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.0291 - accuracy: 0.9960 - val_loss: 13.7180 - val_accuracy: 0.5467\n",
            "Epoch 167/200\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.0699 - accuracy: 0.9920 - val_loss: 13.9804 - val_accuracy: 0.5533\n",
            "Epoch 168/200\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 0.0872 - accuracy: 0.9920 - val_loss: 16.9492 - val_accuracy: 0.5267\n",
            "Epoch 169/200\n",
            "25/25 [==============================] - 6s 255ms/step - loss: 3.9502e-04 - accuracy: 1.0000 - val_loss: 20.9945 - val_accuracy: 0.5067\n",
            "Epoch 170/200\n",
            "25/25 [==============================] - 6s 253ms/step - loss: 0.0536 - accuracy: 0.9920 - val_loss: 8.4282 - val_accuracy: 0.6533\n",
            "Epoch 171/200\n",
            "25/25 [==============================] - 7s 261ms/step - loss: 5.1062e-04 - accuracy: 1.0000 - val_loss: 21.6814 - val_accuracy: 0.5067\n",
            "Epoch 172/200\n",
            "25/25 [==============================] - 6s 254ms/step - loss: 0.0477 - accuracy: 0.9960 - val_loss: 18.6114 - val_accuracy: 0.5533\n",
            "Epoch 173/200\n",
            "25/25 [==============================] - 6s 253ms/step - loss: 6.2469e-07 - accuracy: 1.0000 - val_loss: 19.1288 - val_accuracy: 0.5200\n",
            "Epoch 174/200\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 0.1433 - accuracy: 0.9840 - val_loss: 22.7924 - val_accuracy: 0.5000\n",
            "Epoch 175/200\n",
            "25/25 [==============================] - 6s 236ms/step - loss: 0.1185 - accuracy: 0.9960 - val_loss: 15.1935 - val_accuracy: 0.5667\n",
            "Epoch 176/200\n",
            "25/25 [==============================] - 6s 239ms/step - loss: 0.0568 - accuracy: 0.9920 - val_loss: 16.0795 - val_accuracy: 0.5533\n",
            "Epoch 177/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.0469 - accuracy: 0.9920 - val_loss: 16.8250 - val_accuracy: 0.5400\n",
            "Epoch 178/200\n",
            "25/25 [==============================] - 6s 238ms/step - loss: 0.0452 - accuracy: 0.9880 - val_loss: 12.0499 - val_accuracy: 0.5800\n",
            "Epoch 179/200\n",
            "25/25 [==============================] - 6s 237ms/step - loss: 0.0546 - accuracy: 0.9920 - val_loss: 14.8304 - val_accuracy: 0.5667\n",
            "Epoch 180/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.0288 - accuracy: 0.9960 - val_loss: 21.3933 - val_accuracy: 0.5133\n",
            "Epoch 181/200\n",
            "25/25 [==============================] - 6s 231ms/step - loss: 1.1760e-04 - accuracy: 1.0000 - val_loss: 18.9714 - val_accuracy: 0.5333\n",
            "Epoch 182/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.0640 - accuracy: 0.9920 - val_loss: 17.2755 - val_accuracy: 0.5600\n",
            "Epoch 183/200\n",
            "25/25 [==============================] - 6s 237ms/step - loss: 0.0429 - accuracy: 0.9920 - val_loss: 18.2230 - val_accuracy: 0.5267\n",
            "Epoch 184/200\n",
            "25/25 [==============================] - 6s 234ms/step - loss: 0.0540 - accuracy: 0.9960 - val_loss: 18.8521 - val_accuracy: 0.5467\n",
            "Epoch 185/200\n",
            "25/25 [==============================] - 6s 229ms/step - loss: 1.0166e-07 - accuracy: 1.0000 - val_loss: 18.5499 - val_accuracy: 0.5333\n",
            "Epoch 186/200\n",
            "25/25 [==============================] - 6s 237ms/step - loss: 0.0047 - accuracy: 0.9960 - val_loss: 28.6942 - val_accuracy: 0.4867\n",
            "Epoch 187/200\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 0.0191 - accuracy: 0.9960 - val_loss: 13.2358 - val_accuracy: 0.5800\n",
            "Epoch 188/200\n",
            "25/25 [==============================] - 6s 238ms/step - loss: 0.2944 - accuracy: 0.9880 - val_loss: 11.4336 - val_accuracy: 0.5800\n",
            "Epoch 189/200\n",
            "25/25 [==============================] - 6s 243ms/step - loss: 0.0387 - accuracy: 0.9960 - val_loss: 21.7867 - val_accuracy: 0.4933\n",
            "Epoch 190/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.1047 - accuracy: 0.9880 - val_loss: 9.7966 - val_accuracy: 0.6200\n",
            "Epoch 191/200\n",
            "25/25 [==============================] - 6s 241ms/step - loss: 0.0265 - accuracy: 0.9960 - val_loss: 16.9445 - val_accuracy: 0.5267\n",
            "Epoch 192/200\n",
            "25/25 [==============================] - 6s 230ms/step - loss: 0.0875 - accuracy: 0.9840 - val_loss: 16.1517 - val_accuracy: 0.5267\n",
            "Epoch 193/200\n",
            "25/25 [==============================] - 6s 242ms/step - loss: 0.0818 - accuracy: 0.9880 - val_loss: 16.9975 - val_accuracy: 0.5533\n",
            "Epoch 194/200\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 6.0215e-05 - accuracy: 1.0000 - val_loss: 17.5101 - val_accuracy: 0.5467\n",
            "Epoch 195/200\n",
            "25/25 [==============================] - 6s 232ms/step - loss: 0.0560 - accuracy: 0.9920 - val_loss: 23.5308 - val_accuracy: 0.4933\n",
            "Epoch 196/200\n",
            "25/25 [==============================] - 6s 238ms/step - loss: 0.0869 - accuracy: 0.9840 - val_loss: 16.3986 - val_accuracy: 0.5533\n",
            "Epoch 197/200\n",
            "25/25 [==============================] - 6s 238ms/step - loss: 1.1579e-05 - accuracy: 1.0000 - val_loss: 18.1437 - val_accuracy: 0.5400\n",
            "Epoch 198/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.0249 - accuracy: 0.9960 - val_loss: 19.3545 - val_accuracy: 0.5467\n",
            "Epoch 199/200\n",
            "25/25 [==============================] - 6s 237ms/step - loss: 0.2133 - accuracy: 0.9920 - val_loss: 18.6653 - val_accuracy: 0.5533\n",
            "Epoch 200/200\n",
            "25/25 [==============================] - 6s 240ms/step - loss: 0.0444 - accuracy: 0.9920 - val_loss: 20.9428 - val_accuracy: 0.5200\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}